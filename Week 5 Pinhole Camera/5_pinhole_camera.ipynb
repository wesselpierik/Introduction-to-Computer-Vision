{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Initialization</a></span></li><li><span><a href=\"#Utilities\" data-toc-modified-id=\"Utilities-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Utilities (some code to be written in this section!)</a></span></li><li><span><a href=\"#Wireframes:-Transforming-and-Drawing\" data-toc-modified-id=\"Wireframes:-Transforming-and-Drawing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Wireframes: Transforming and Drawing</a></span></li><li><span><a href=\"#The-Pinhole-Camera\" data-toc-modified-id=\"The-Pinhole-Camera-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The Pinhole Camera</a></span></li><li><span><a href=\"#Camera-Calibration\" data-toc-modified-id=\"Camera-Calibration-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Camera Calibration</a></span></li><li><span><a href=\"#Augmented-Reality\" data-toc-modified-id=\"Augmented-Reality-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Augmented Reality</a></span><ul class=\"toc-item\"></ul></li><li><span><a href=\"#From-2D-to-3D\" data-toc-modified-id=\"From-2D-to-3D-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>From 2D to 3D</a></span><ul class=\"toc-item\"></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICV INF-LabExercise: The Pinhole Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "import cv2\n",
    "from matplotlib.patches import ConnectionPatch\n",
    "from matplotlib.collections import LineCollection\n",
    "from mpl_toolkits.mplot3d.art3d import Line3DCollection\n",
    "from scipy.linalg import svd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden in this cell are some $\\LaTeX$ macros\n",
    "$\\renewcommand{\\v}[1]{\\mathbf #1}$\n",
    "$\\newcommand{\\hv}[1]{\\widetilde{\\mathbf #1}}$\n",
    "$\\newcommand{\\setR}{\\mathbb R}$\n",
    "$\\newcommand{\\T}{^\\top}$\n",
    "$\\newcommand{\\inv}{^{-1}}$\n",
    "$\\newcommand{\\pfrac}[2]{\\frac{\\partial #1}{\\partial #2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints(kps, nkps=None, ax=None, marker='x', \n",
    "                   marker_size=10, scale_and_orientation=True):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if nkps is None:\n",
    "        nkps = len(kps)\n",
    "    xs = [kp.pt[0] for kp in kps]\n",
    "    ys = [kp.pt[1] for kp in kps]\n",
    "    ax.scatter(xs, ys, marker=marker)\n",
    "    if scale_and_orientation:\n",
    "        for kp in kps[:nkps]:\n",
    "            x, y = kp.pt\n",
    "            r = kp.size / 2\n",
    "            angle = kp.angle/2/np.pi\n",
    "            ax.add_artist(plt.Circle((kp.pt), kp.size/2, \n",
    "                                     color='green', fill=False))\n",
    "            ax.add_artist(plt.Arrow(x, y, r*np.cos(angle), \n",
    "                                    r*np.sin(angle), color='red'))\n",
    "            \n",
    "\n",
    "\n",
    "def draw_matches(f1, kps1, f2, kps2, matches, \n",
    "                 horizontal=True, figsize=(15,15)):\n",
    "    if horizontal:\n",
    "        fig, axs = plt.subplots(1,2, figsize=figsize)\n",
    "    else:\n",
    "        fig, axs = plt.subplots(2,1, figsize=figsize)\n",
    "    \n",
    "    axs[0].imshow(f1)\n",
    "    axs[1].imshow(f2)\n",
    "    \n",
    "    # get the indexes of the matches\n",
    "    idx1 = [m.queryIdx for m in matches]\n",
    "    idx2 = [m.trainIdx for m in matches]\n",
    "    \n",
    "    xs1 = [kps1[i].pt[0] for i in idx1]\n",
    "    ys1 = [kps1[i].pt[1] for i in idx1]\n",
    "    xs2 = [kps2[i].pt[0] for i in idx2]\n",
    "    ys2 = [kps2[i].pt[1] for i in idx2]\n",
    "    \n",
    "    \n",
    "    for x1, y1, x2, y2 in zip(xs1, ys1, xs2, ys2):\n",
    "        con = ConnectionPatch(xyA=(x1, y1), xyB=(x2, y2), coordsA=\"data\", coordsB=\"data\",\n",
    "                      axesA=axs[0], axesB=axs[1], color='g')\n",
    "        axs[1].add_artist(con)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_row(imttllist, axs=False):\n",
    "    n = len(imttllist)\n",
    "    for i, imttl in enumerate(imttllist):\n",
    "        if imttl is None:\n",
    "            continue\n",
    "        im, ttl = imttl\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.imshow(im, cmap='gray')\n",
    "        if not axs:\n",
    "            plt.axis('off')\n",
    "        plt.title(ttl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also find some use for the ``e2h`` and ``h2e`` functions. We give them to you here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e2h(x):\n",
    "    if len(x.shape) == 1:\n",
    "        return np.hstack((x, [1]))\n",
    "    return np.vstack((x, np.ones(x.shape[1])))\n",
    "    \n",
    "def h2e(tx):\n",
    "    return tx[:-1]/tx[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wireframes: Transforming and Drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab exercise we will often find the need to define, transform and draw wireframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a wireframe as a collection of vertices (points) in 2D or 3D and a collection of edges, each edge linking two of the vertices. The vertices are represented with an array of shape (n,d) (with d the dimension, i.e. 2 or 3). The edges are encoded in an array of shape (m,2) where each row is a pair of integers, say (i, j) linking vertices[i] with vertices[j]. As a simple example: the unit square in 2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_square = (np.array([[0, 0], [1, 0], [1, 1], [0, 1]]),\n",
    "               np.array([[0, 1], [1, 2], [2, 3], [3, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the unit cube in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_cube = (np.array([[0, 0, 0], [1, 0, 0], [1, 1, 0], [0, 1, 0],\n",
    "                       [0, 0, 1], [1, 0, 1], [1, 1, 1], [0, 1, 1]]),\n",
    "             np.array([[0, 1], [1, 2], [2, 3], [3, 0],\n",
    "                       [4, 5], [5, 6], [6, 7], [7, 4],\n",
    "                       [0, 4], [1, 5], [2, 6], [3, 7]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a function to make a drawing of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_wireframe(ax, wf, colors='red', lw=2, adapt=True):\n",
    "    \"\"\"draw a 2D or 3D wireframe. \n",
    "    The vertices argument is a (n,2(3)) shaped array where\n",
    "    each row is a (x,y (,z)) coordinate pair of a vertex and \n",
    "    edges is (m,2) array where each row is a tuple (i, j) \n",
    "    indicating that vertex[i] is connected with \n",
    "    vertex[j] with a straight line\"\"\"\n",
    "    vertices, edges = wf\n",
    "    segments = np.array([(vertices[i], vertices[j]) for i, j in edges])\n",
    "    \n",
    "    twoD = vertices.shape[1] == 2\n",
    "    if twoD:\n",
    "        lines = LineCollection(segments, colors=colors)\n",
    "        ax.add_artist(lines)\n",
    "        \n",
    "        if adapt:\n",
    "            # now adjust the xlim and ylim \n",
    "            # to incorporate the added wireframe\n",
    "            # (seems mpl doesn't do that automatically)\n",
    "            # we take the bounding box of the set limits and\n",
    "            # the new wireframe limits\n",
    "            vxmn, vymn = np.min(vertices, axis=0)\n",
    "            vxmx, vymx = np.max(vertices, axis=0)\n",
    "                    \n",
    "            axmn, axmx = ax.get_xlim()\n",
    "            aymn, aymx = ax.get_ylim()\n",
    "                        \n",
    "            if aymn > aymx:\n",
    "                # true when an image is shown\n",
    "                yaxreversed = True\n",
    "                aymn, aymx = aymx, aymn \n",
    "            else:\n",
    "                yaxreversed = False\n",
    "            \n",
    "            axmn = np.minimum(vxmn, axmn)\n",
    "            axmx = np.maximum(vxmx, axmx)\n",
    "            ax.set_xlim(axmn, axmx)\n",
    "        \n",
    "            aymn = np.minimum(vymn, aymn)\n",
    "            aymx = np.maximum(vymx, aymx)\n",
    "                        \n",
    "            if yaxreversed:\n",
    "                ax.set_ylim(aymx, aymn)\n",
    "            else:\n",
    "                ax.set_ylim(aymn, aymx)\n",
    "        \n",
    "    else:\n",
    "        lines = Line3DCollection(segments, colors=colors)\n",
    "        ax.add_collection3d(lines)\n",
    "        \n",
    "        if adapt:\n",
    "            # now adjust the xlim, ylim and zlim\n",
    "            # to incorporate the added wireframe\n",
    "            # (seems mpl doesn't do that automatically)\n",
    "            # we take the bounding box of the set limits and\n",
    "            # the new wireframe limits\n",
    "            vxmn, vymn, vzmn = np.min(vertices, axis=0)\n",
    "            vxmx, vymx, vzmx = np.max(vertices, axis=0)\n",
    "        \n",
    "            axmn, axmx = ax.get_xlim()\n",
    "            aymn, aymx = ax.get_ylim()\n",
    "            azmn, azmx = ax.get_zlim()\n",
    "            \n",
    "            axmn = np.minimum(vxmn, axmn)\n",
    "            axmx = np.maximum(vxmx, axmx)\n",
    "            \n",
    "            ax.set_xlim(axmn, axmx)\n",
    "        \n",
    "            aymn = np.minimum(vymn, aymn)\n",
    "            aymx = np.maximum(vymx, aymx)\n",
    "            \n",
    "            ax.set_ylim(aymn, aymx)\n",
    "        \n",
    "            azmn = np.minimum(vzmn, azmn)\n",
    "            azmx = np.maximum(vzmx, azmx)\n",
    "            \n",
    "            ax.set_zlim(azmn, azmx)\n",
    "        \n",
    "            ## Note: there should be a way to do the axis limits settings\n",
    "            ## independent of the dimension...\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(121)\n",
    "draw_wireframe(ax, unit_square)\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "draw_wireframe(ax, unit_cube);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately it is not possible to set the aspect ratio of 3D axes in Matplotlib (only the aspect ratio of the entire figure influences the aspect ratio of the plot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a 3D rotation by a single vector: the direction of the vector gives the axis of rotation, and the length of the vector can be the angle. Python can do this for us, and we can apply the transformation to the unit cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.transform import Rotation as R\n",
    "r = R.from_rotvec(np.pi/2*np.array([1,1,1])/np.sqrt(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v, e = unit_cube\n",
    "vr = r.apply(v)\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "draw_wireframe(ax, (v,e))\n",
    "draw_wireframe(ax, (vr,e), colors='green')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3.1\n",
    "\n",
    "To give our pinhole camera in the next section something more challenging to look at you have to define a house wireframe. Start with the cube and add two vertices at (0.5, 0, 1.5) and (0.5, 1, 1.5) and add the appropriate edges (5 edges extra) to make the shape of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60beb8793bf8ce75",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def wireframe_house():\n",
    "    \"\"\"\n",
    "    Return a wireframe (pair of vertices, edges) in the shape of a house:\n",
    "    add vertices and edges to the cube defined earlier, as described above.\n",
    "    \n",
    "    (Do not get the cube from the global namespace; if you want to use it,\n",
    "    copy its definition into this function.)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n",
    "    return vertices, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f793fa78d8b89dc8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "house = wireframe_house()\n",
    "assert len(house) == 2, \"`house` should be a tuple of two arrays: one of vertices, one of edges.\"\n",
    "\n",
    "assert any(np.array_equal(np.array([0.5, 0., 1.5]), x) for x in house[0]), \"At least one roof vertex is missing.\"\n",
    "assert any(np.array_equal(np.array([0.5, 1., 1.5]), x) for x in house[0]), \"One roof vertex is missing.\"\n",
    "assert house[0].shape == (10, 3), \"Do you have the right number of vertices in your house?\"\n",
    "assert house[1].shape == (17, 2), \"Do you have the right number of edges in your house?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "draw_wireframe(ax, house)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's make it real Dutch: a row of 3 houses. Not three completely different houses but scaled and translated versions of our 'unit' house. You should position the three houses besides each other in x direction. The first house ``house1`` should start at (0,0,0) with depth (in the y direction) of 1 and height 1.5 (i.e. ``house1`` is ``house``). The second house should start at (1,0,0) but now with width 1.5 and height 2. The third house should be right next to house2 and have width 2 and height 1.2.\n",
    "\n",
    "The catch is that you may not define new wireframes from scratch. You *have* to use transformations like scaling and translations to obtain the results.\n",
    "\n",
    "### Assignment 3.2\n",
    "\n",
    "Implement the following three functions, which are used for scaling and translating wireframes, and applying arbitrary projective transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b6182a2256083e1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Complete all three functions below.\n",
    "# You should use the transform_3d_wireframe function\n",
    "# in the scale_3d_wireframe and translate_3d_wireframe functions\n",
    "\n",
    "def transform_3d_wireframe(wf, A):\n",
    "    \"\"\"\n",
    "    Transform a 3d wireframe with the given projective transformation (matrix) A.\n",
    "    \n",
    "    Note that the ordering of the vertices and edges should be unchanged, only the coordinates of the vertices\n",
    "    should be transformed.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def scale_3d_wireframe(wf, sx, sy, sz):\n",
    "    \"\"\"\n",
    "    Scale wireframe wf by factors (sx, sy, sz) in the x, y, z direction respectively.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def translate_3d_wireframe(wf, tx, ty, tz):\n",
    "    \"\"\"\n",
    "    Translate wireframe wf by distances (tx, ty, tz) in the x, y, z direction respectively.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-c9a734ec69acc641",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Tests with a very simple wireframe.\n",
    "test_wf = (np.array([[0, 0, 0], [1, 0, 0]]), np.array([[0, 1]]))\n",
    "\n",
    "A = np.array([[1., 0., 0., 1.],\n",
    "             [1., 1., 0., 0.],\n",
    "             [0., 0., 1., 1.],\n",
    "             [0., 0., 0., 1.]])\n",
    "\n",
    "transformed_wf = transform_3d_wireframe(test_wf, A)\n",
    "assert type(transformed_wf) == tuple and len(transformed_wf) == 2, \"The output should again be a wireframe.\"\n",
    "assert transformed_wf[0].shape == (2, 3) and transformed_wf[1].shape == (1, 2), \\\n",
    "    \"The resulting wireframe should have the same shape.\"\n",
    "assert np.array_equal(transformed_wf[1], test_wf[1]), \"The incidence relations should be unchanged.\"\n",
    "assert np.allclose(transformed_wf[0][0, :], np.array([1., 0., 1.]))\n",
    "\n",
    "translated_wf = translate_3d_wireframe(test_wf, 1, 2, 3)\n",
    "assert type(translated_wf) == tuple and len(translated_wf) == 2, \"The output should again be a wireframe.\"\n",
    "assert translated_wf[0].shape == (2, 3) and translated_wf[1].shape == (1, 2), \\\n",
    "    \"The resulting wireframe should have the same shape.\"\n",
    "assert np.array_equal(translated_wf[1], test_wf[1]), \"The incidence relations should be unchanged.\"\n",
    "assert np.allclose(translated_wf[0][0, :], np.array([1, 2, 3]))\n",
    "\n",
    "scaled_wf = translate_3d_wireframe(translated_wf, 2, 3, 4)\n",
    "assert type(scaled_wf) == tuple and len(scaled_wf) == 2, \"The output should again be a wireframe.\"\n",
    "assert scaled_wf[0].shape == (2, 3) and scaled_wf[1].shape == (1, 2), \\\n",
    "    \"The resulting wireframe should have the same shape.\"\n",
    "assert np.array_equal(translated_wf[1], scaled_wf[1]), \"The incidence relations should be unchanged.\"\n",
    "assert np.allclose(scaled_wf[0][1, :], np.array([4, 5, 7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3.3\n",
    "\n",
    "Use the functions you have defined above to define the variables `house1`, `house2`, `house3`, as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d26df7aa753004f",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def three_houses():\n",
    "    \"\"\" \n",
    "    Return wireframes (house1, house2, house3), using scaling and translation of\n",
    "    the house given by `wireframe_house`. Note that house1 is just equal to the original house.\n",
    "    \n",
    "    The description of the houses is given above.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n",
    "    return house1, house2, house3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house1, house2, house3 = three_houses()\n",
    "fig = plt.figure(figsize=(7,5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "draw_wireframe(ax, house1)\n",
    "draw_wireframe(ax, house2)\n",
    "draw_wireframe(ax, house3);\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, these 3D drawings, aren't they? But wait, 3D? On a 2D computer screen? That is what the pinhole camera is all about. How to project the 3D world onto a 2D screen (or retina, or camera plane). And that (or a simplification thereof) is what is done in the 3D drawing functions in Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section you will experiment with the pinhole camera model as preparation for the final goal in this lab exercise, namely to estimate the pinhole camera model parameters from real images. So the final goal is different from what is done in computer graphics where the camera matrix is given (selected by the user or programmer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Pinhole Camera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture notes the pinhole camera was defined with the matrix $P$ mapping 3D coordinates onto a 2D plane:\n",
    "\\begin{align}\n",
    "\\hv x &\\sim P\\,\\hv X\n",
    "\\end{align}\n",
    "where $\\hv x = (x\\; y\\; 1)\\T$ is the homogeneous representation of a 2D point with coordinates $(x,y)$ and $\\hv X = (X\\; Y\\; Z\\; 1)\\T$ is the homogeneous representation of the 3D point with coordinates $(X,Y,Z)$. Please note the use of $\\sim$ where you might have expected $=$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera matrix $P$ can be written as:\n",
    "\\begin{align}\n",
    "    P = \\underbrace{\\begin{bmatrix}\n",
    "    f_x & \\gamma & u_0\\\\\n",
    "    0 & f_y & v_0\\\\\n",
    "    0 & 0 & 1\n",
    "    \\end{bmatrix}}_{P_{\\mbox{internal}}}\\,\n",
    "    \\underbrace{\\begin{bmatrix}\n",
    "    R\\T & -R\\T\\v t\n",
    "    \\end{bmatrix}}_{P_{\\mbox{external}}}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $R$ is the rotation matrix and $\\v t$ the translation that together determine the position of the camera in the 'real world'. Note that the last matrix (the external camera matrix) is in block form, its elementwise shape is $3\\times4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section you have to construct both the internal matrix and external matrix according to geometrical specifications. Then you have to project a 3D wiremodel onto the 2D (retina) plane. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that a 3D point $\\v X_c = (X_c\\; Y_c\\; Z_c)\\T$  with coordinates given with respect to the *camera frame* is projected on the retina as:\n",
    "\\begin{align}\n",
    "\\hv x \\sim \\begin{bmatrix}\n",
    "    f_x & \\gamma & u_0\\\\\n",
    "    0 & f_y & v_0\\\\\n",
    "    0 & 0 & 1\n",
    "    \\end{bmatrix} \\v X_c\n",
    "    \\end{align}\n",
    "In the camera frame the $Z$ axis is pointing towards the scene (the optical axis). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw a camera in a scene it is customary in computer graphics and computer vision to draw the *frustum*: a small pyramid with a rectangular 'ground' plane (representing the size of the retina) and the top of the pyramid being the origin of the camera coordinate system. The pyramid indicates the field of view of the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples in these notes we will model a camera with a focal distance of 50 mm. Furthermore we assume the distances on the retina are measured in mm as well (in fact we will measure all distances for now in milimeters) and that the origin of the 2D coordinates on the retina are measured relative to an origin coinciding with the optical axis. Remember that the optical axis is the Z-axis in the camera coordinate system. Lastly we assume a skewless camera. This should be enough information for you to numerically define the internal camera matrix.\n",
    "\n",
    "### Assignment 4.1\n",
    "\n",
    "Define the internal camera matrix, as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8d2d3bd60ea1c7f5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_P_intern(focal_distance=50):\n",
    "    \"\"\"\n",
    "    Return the internal camera matrix (numpy array) for a given focal distance, as\n",
    "    given by the information above.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw the frustum we need to know where the camera is in the world coordinate system. That is why in the ``draw_frustum`` function we need both the internal and external camera matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnx = -18 # these are the sizes of the 35 mm film in classical camera's\n",
    "mxx = +18 # still compatible with high end digital camera's\n",
    "mny = -12\n",
    "mxy = +12\n",
    "P_intern = get_P_intern()\n",
    "P_intern = P_intern/P_intern[2,2]\n",
    "fl = P_intern[0,0]\n",
    "frustum = (np.array([[0,0,0], [mnx,mny,fl], [mxx,mny,fl], [mxx,mxy,fl], [mnx,mxy,fl]]),\n",
    "           np.array([[0,1], [0,2], [0,3], [0,4],\n",
    "                     [1,2], [2,3], [3,4], [4,1]]))\n",
    "opt_axis = (np.array([[0, 0, 0], [0, 0, 5*fl]]),\n",
    "            np.array([[0,1]]))\n",
    "\n",
    "def draw_frustum(ax, P_intern, P_extern, optax=True, scale=1):\n",
    "    F = inv(np.vstack((P_extern, np.array([[0,0,0,1]]))))\n",
    "    sf = scale_3d_wireframe(frustum, scale, scale, scale)\n",
    "    Fsf = transform_3d_wireframe(sf, F)\n",
    "    draw_wireframe(ax, Fsf)    \n",
    "    if optax:\n",
    "        sax = scale_3d_wireframe(opt_axis, scale, scale, scale)\n",
    "        Fsax = transform_3d_wireframe(sax, F)\n",
    "        draw_wireframe(ax, Fsax, colors='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below should result in a picture like shown below: note the sizes of the 'retina'.\n",
    "<img src=\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_static/frustum_35mm.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "P_extern = np.column_stack((np.eye(3), np.zeros(3))) # 'identity'\n",
    "draw_frustum(ax, P_intern, P_extern, scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells, we are going to make a more realistic scene with the three houses and one camera. **All measurements are in millimeters.**\n",
    "\n",
    "1. The camera is at location (0,0,1700) and pointing in the y direction and has focal length 50mm (and no translation internally and skew zero)\n",
    "\n",
    "1. The front of the houses are at 20000 mm away from the camera (on the ground of course which is at z=0) and the unit house (``house1``) has a square base area of 4000 mm and a height of 6000 mm. The other houses scale up the same.\n",
    "\n",
    "You have defined P_intern, as well as the three houses. We can scale and translate the houses to fit the requirements. The only thing we still have to define is `P_extern`.\n",
    "\n",
    "Note that when rotating the 3d world frame such that the z-axis is pointing towards the houses (i.e. in the y direction of the world frame) you can't line up both the x and y axes of the camera frame up with the x and y axes of the world frame. You have to make a choice.\n",
    "\n",
    "In the code below, the definition of `P_extern`, we expect you to align the y axes of both frames. We will then correct for the inversion of the x axis (that is the consequence of this choice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of your code should be something like\n",
    "\n",
    "<img src=\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_static/scene_cam.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4.2\n",
    "\n",
    "Finish the function below, to get the right picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_P_extern(distance=1700):\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9850a20896fa13be",
     "locked": false,
     "points": 4,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P_intern = get_P_intern()\n",
    "\n",
    "P_extern = get_P_extern()\n",
    "\n",
    "house1, house2, house3 = three_houses()\n",
    "\n",
    "house1mm = scale_3d_wireframe(house1, 4000, 4000, 4000)\n",
    "house1mm = translate_3d_wireframe(house1mm, -9000, 20000, 0)\n",
    "\n",
    "house2mm = scale_3d_wireframe(house2, 4000, 4000, 4000)\n",
    "house2mm = translate_3d_wireframe(house2mm, -9000, 20000, 0)\n",
    "\n",
    "house3mm = scale_3d_wireframe(house3, 4000, 4000, 4000)\n",
    "house3mm = translate_3d_wireframe(house3mm, -9000, 20000, 0)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "draw_frustum(ax, P_intern, P_extern, scale=100) ## large scale needed to see the frustum\n",
    "draw_wireframe(ax, house1mm)\n",
    "draw_wireframe(ax, house2mm)\n",
    "draw_wireframe(ax, house3mm)\n",
    "\n",
    "lines_to_inf = (np.array([[-1000,0,0], [-1000,20000,0],\n",
    "                          [1000, 0, 0], [1000, 20000, 0]]),\n",
    "                np.array([[0,1], [2,3]]))\n",
    "draw_wireframe(ax, lines_to_inf, colors='b')\n",
    "ax.set_zlim(0, 10000);\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are in a position to see what the camera 'sees'. The result of the next cell should be something like\n",
    "<img src=\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_static/scene_view1.png\" width=\"800\" />\n",
    "\n",
    "Note the ordering of the houses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = P_intern @ P_extern\n",
    "\n",
    "house1p = transform_3d_wireframe(house1mm, P)\n",
    "house2p = transform_3d_wireframe(house2mm, P)\n",
    "house3p = transform_3d_wireframe(house3mm, P)\n",
    "\n",
    "# note the y-coordinate of the lines start at 1 \n",
    "# (instead of 0 in the previous 3D drawing)\n",
    "lines_to_inf = (np.array([[-1000, 1,0], [-1000,20000,0],\n",
    "                          [1000, 1, 0], [1000, 20000, 0]]),\n",
    "                np.array([[0,1], [2,3]]))\n",
    "\n",
    "linesp = transform_3d_wireframe(lines_to_inf, P)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "draw_wireframe(ax, house1p)\n",
    "draw_wireframe(ax, house2p)\n",
    "draw_wireframe(ax, house3p)\n",
    "\n",
    "draw_wireframe(ax, linesp, colors='b', adapt=True) # this will enlarge the viewport... \n",
    "\n",
    "ax.set_xlim(-18, +18) # The standard format for 135 film ('kleinbeeldcamera')\n",
    "ax.set_ylim(-12, +12) # idem\n",
    "ax.invert_xaxis() # correction for the x-inversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we redefine `P_extern` to set the camera much further from the houses (i.e. at a negative y coordinate, say $y=-50000$). We leave the other parameters, like the viewport (x and y limits) the same, i.e. the way we have set the axes limits in the previous code block.\n",
    "\n",
    "As a result, the scene will look almost like an 'affine projection', where we only see the fronts of the houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_extern = np.array([[   -1,     0,     0,     0],\n",
    "       [    0,     0,     1, -1700],\n",
    "       [    0,     1,     0, 50000]])\n",
    "\n",
    "P = P_intern @ P_extern\n",
    "\n",
    "house1p = transform_3d_wireframe(house1mm, P)\n",
    "house2p = transform_3d_wireframe(house2mm, P)\n",
    "house3p = transform_3d_wireframe(house3mm, P)\n",
    "\n",
    "# note the y-coordinate of the lines start at 1 \n",
    "# (instead of 0 in the previous 3D drawing)\n",
    "lines_to_inf = (np.array([[-1000, 1,0], [-1000,20000,0],\n",
    "                          [1000, 1, 0], [1000, 20000, 0]]),\n",
    "                np.array([[0,1], [2,3]]))\n",
    "\n",
    "linesp = transform_3d_wireframe(lines_to_inf, P)\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "draw_wireframe(ax, house1p)\n",
    "draw_wireframe(ax, house2p)\n",
    "draw_wireframe(ax, house3p)\n",
    "\n",
    "draw_wireframe(ax, linesp, colors='b') # this will enlarge the viewport... \n",
    "\n",
    "ax.set_xlim(-18, +18) # explicitly set the viewport of the 135 film camera\n",
    "ax.set_ylim(-12, +12)\n",
    "ax.invert_xaxis() # and correct for the x axis inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of camera calibration is to find the numerical relation\n",
    "between the three dimensional points and the two dimensional points\n",
    "where these are projected. Thus we have to find the camera matrix $P$\n",
    "that projects points $(X,Y,Z)$ (in world coordinates) onto the 2D\n",
    "points $(x,y)$ in the image:\n",
    "\\begin{align}\n",
    "   \\hv x \\sim P \\hv X\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture notes it is demonstrated that, given the point correspondences $\\hv x_i\n",
    "\\leftrightarrow \\hv X_i$ for $i=1,\\ldots,n$, we have to solve:\n",
    "\\begin{align}\n",
    "   \\begin{bmatrix}\n",
    "   \\hv X_1\\T & \\v 0\\T & -x_1 \\hv X_1\\T \\\\\n",
    "   \\v 0\\T & \\hv X_1\\T & -y_1 \\hv X_1\\T \\\\\n",
    "   \\vdots & \\vdots & \\vdots \\\\\n",
    "   \\hv X_n\\T & \\v 0\\T & -x_n \\hv X_n\\T \\\\\n",
    "   \\v 0\\T & \\hv X_n\\T & -y_n \\hv X_n\\T \\\\\n",
    "   \\end{bmatrix}\n",
    "   \\v p = \\v 0 \\\\\n",
    "   A \\v p = \\v 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5.1\n",
    "\n",
    "To find a null vector of $A$ we can use the same 'SVD trick' that we\n",
    "have used to find the perspecive transform relating 2D points in one\n",
    "image with 2D points in another image (now we are relating 3D points\n",
    "with 2D points).\n",
    "\n",
    "Given a null vector $\\v p$ we can reshape it into the required camera\n",
    "matrix $P$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7131af351754f35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calibrate_pinhole_camera(xy, XYZ):\n",
    "    \"\"\"\n",
    "    Use the SVD trick to find the transformation that most closely\n",
    "    matches the transformation of the points given in XYZ (in 3D \n",
    "    Euclidean coordinates) to xy (in 2D Euclidean coordinates).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your calibration function we will use the following image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f = plt.imread('calibrationpoints.jpg')\n",
    "except FileNotFoundError:\n",
    "    wget.download('https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_images/calibrationpoints.jpg')\n",
    "    f = plt.imread('calibrationpoints.jpg')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(f)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this image we have marked 18 points in the image these are collected in the array ``xy``. The checker board patterns on the two perpendicular sides of the box depicted in the image allow us to pinpoint these 18 points in 3D coordinates as well (collected in the array ``XYZ``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[ 213.1027,  170.0499], [ 258.1908,  181.3219],\n",
    "               [ 306.41  ,  193.8464], [ 351.498 ,  183.8268],\n",
    "               [ 382.8092,  155.6468], [ 411.6155,  130.5978],\n",
    "               [ 223.7485,  218.2691], [ 267.5841,  230.7935],\n",
    "               [ 314.5509,  244.5705], [ 357.7603,  235.1771],\n",
    "               [ 387.819 ,  205.1184], [ 415.3728,  178.1908],\n",
    "               [ 234.3943,  263.9834], [ 276.9775,  277.1341],\n",
    "               [ 323.318 ,  291.5372], [ 363.3963,  282.1438],\n",
    "               [ 392.8288,  251.4589], [ 419.1301,  223.9051]])\n",
    "\n",
    "XYZ = np.array([[0, -5, 5], [0, -3, 5], [0, -1, 5], [-1, 0, 5],\n",
    "                [-3, 0, 5], [-5, 0, 5], [0, -5, 3], [0, -3, 3],\n",
    "                [0, -1, 3], [-1, 0, 3], [-3, 0, 3], [-5, 0, 3],\n",
    "                [0, -5, 1], [0, -3, 1], [0, -1, 1], [-1, 0, 1],\n",
    "                [-3, 0, 1], [-5, 0, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we draw the image again and plot the 2D points from array ``xy`` on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(f)\n",
    "plt.scatter(xy[:,0], xy[:,1], marker='x');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Numerical test of calibration function\n",
    "P = calibrate_pinhole_camera(xy, XYZ)\n",
    "P = P/P[-1,-1]\n",
    "assert np.allclose(P, np.array([\n",
    "    [-2.53380724e+01,  1.76724681e+01, -9.75963068e+00, 3.50812662e+02],\n",
    "    [ 8.94324977e+00,  1.92571438e+00, -2.83187164e+01, 3.22243837e+02],\n",
    "    [-2.69423514e-02, -1.94940227e-02, -1.86848368e-02, 1.00000000e+00]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you pass the numerical test of your calibration function we can do a more insightful test. We take the the 3D points in array ``XYZ`` and project each of the points (the rows) using the camera matrix $P$. Evidently we expect the projected points are close to the points in the ``xy`` matrix.\n",
    "\n",
    "### Assignment 5.2\n",
    "\n",
    "Implement the following function, which applies a projection matrix P to an array of points (given in Euclidean coordinates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6b46e7ecac1a7fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def project_points(P, XYZ):\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b834d992b03b3463",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(\n",
    "    project_points(np.column_stack((np.eye(3), np.array([1, 2, 3]))), np.array([[1, 0, 0], [0, 2, 3]])),\n",
    "    np.array([[2/3, 2/3], [1/6, 2/3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_p = project_points(P, XYZ)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(f)\n",
    "plt.scatter(xy[:,0], xy[:,1], marker='x');\n",
    "plt.scatter(xy_p[:,0], xy_p[:,1], marker='o');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(f)\n",
    "plt.scatter(xy[:,0], xy[:,1], marker='x');\n",
    "plt.scatter(xy_p[:,0], xy_p[:,1], marker='o');\n",
    "plt.xlim(200, 400)\n",
    "plt.ylim(300, 150); # note the 'strange' order: to keep the same orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did it correctly, the difference between the points in ``xy`` and ``xy_p`` should be barely noticible. A quantative measure is the **reprojection error** as the average of the Euclidean distances between the points in ``xy`` and ``xy_p``.\n",
    "\n",
    "### Assignment 5.3\n",
    "\n",
    "Write a function that computes the reprojection error: the average of the Euclidean distances of the vectors in `xy` and the results of their reprojection `xy_p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-cc94e22e4855e561",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reprojection_error(xy, xy_p):\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(reprojection_error(xy, xy_p), 0.42166688)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmented Reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image that we have shown in the previous section depicts the real world. Now that we are able to calculate the camera matrix $P$ relating 3D coordinates to the image coordinates we can use computer graphic techniques to draw computer generated images of objects into the scene depicted in the image. In this exercise we keep things simple: the only objects we will draw are wireframe models. For more convincing and lifelike augmented reality we refer to a computer graphics course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can take the unit cube and draw it in the scene (i.e. on top of the image) at the origin of the 3D coordinate frame. This should result in something like this:\n",
    "<img src=\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_static/drawcubeorigin.png\" width=\"600\" />\n",
    "\n",
    "With the functions you have implemented, together with the draw_wireframe function from before, it is be easy to place cubes on top of this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cube(ax, P, X, Y, Z):\n",
    "    cube_at_XYZ = translate_3d_wireframe(unit_cube, X, Y, Z)\n",
    "    cube_p = transform_3d_wireframe(cube_at_XYZ, P)\n",
    "    draw_wireframe(ax, cube_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(f)\n",
    "draw_cube(ax, P, 0, 0, 0)\n",
    "draw_cube(ax, P, 0, -7, 6)\n",
    "draw_cube(ax, P, -4, 0, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Bonus) Animation (3pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** before you start working on the this bonus exercise there is one more exercise section right after this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bonus for this lab exercise is to take the calibration and image done in the previous section and make an animation of a cube moving along a 3D circle $x^2+y^2=r^2$ and $z=0$ (i.e. as if it shifts over the table surface).\n",
    "\n",
    "To complete this bonus exercise, upload your animation in a format most video players will be able to handle, and hand it in together with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From 2D to 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The camera matrix $P$ maps 3D points in world coordinates onto 2D coordinates in camera coordinates. Be sure to understand that this mapping is **not invertible.** Does that mean that we cannot reconstruct the 3D world from (one or more) 2D images? O yes we can!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general we need more than one image from the same scene taken from different viewpoints. A bit like the brain is able to reconstruct 3D space by looking with two eyes (To illustrate the need for two eyes, stretch you arms forwards in front of you but not extended completely, start with your hands far away from eachother. Point your index fingers of both hands towards eachother and **while having one eye closed** bring your hands together in a smooth movement and let the tops of two index fingers meet. Not many people succeed.) Looking with two eyes is called stereo vision and is an important subject in Computer Vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even given only one image we can do some sort of 3D reconstruction. Instead of a second eye you could project a pattern on the objects in the scene and then you can reconstruct the 3D positions of the pattern points seen in the image. This is a very simplified view of how the Kinect camera works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even more simple solutions are practical in some situations. For instance if there is knowledge on which 3D plane a 2D point (x,y) lies you can reconstruct the 3D position (X,Y,Z) given the camera matrix $P$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A plane in 3D space can be represented as:\n",
    "\\begin{align}\n",
    "a X + b Y + c Z + d = 0\n",
    "\\end{align}\n",
    "Using homogeneous coordinates we can write:\n",
    "\\begin{align}\n",
    "\\begin{bmatrix}a & b & c & d\\end{bmatrix}\\,\n",
    "\\begin{bmatrix}X \\\\ Y \\\\ Z\\\\ 1\\end{bmatrix} = 0\n",
    "\\end{align}\n",
    "or\n",
    "\\begin{align}\n",
    "\\hv N\\T\\, \\hv X = 0\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the assumption is we know the plane $\\hv p$, but we are also given a 2D point that is the projection $\\hv x \\sim P\\,\\hv X$ of a 3D point $\\hv X$ on the plane $\\hv N$. Summarizing we know:\n",
    "\\begin{align}\n",
    "\\hv N\\T\\, \\hv X &= 0\\\\\n",
    "\\hv x &\\sim P\\,\\hv X\n",
    "\\end{align}\n",
    "where $\\hv X$ is the only unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 7.1\n",
    "\n",
    "In ANS question 3(a), you are asked to algebraically solve the system above to obtain a way to calculate $\\tilde {\\bf X}$. Implement your solution (in case you need more than a few lines of code, your mathematical solution is possibly wrong; think again or ask for help)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(tN, P, tx):\n",
    "    # YOUR CODE HERE (Replace this and the following line with your code)\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and test your solution on a few points in the ground plane for which the (X,Y,Z) coordinates are known:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XYZgp = np.array([[0,0,0],\n",
    "                  [-2,0,0],\n",
    "                  [-5,0,0],\n",
    "                  [0,-2,0],\n",
    "                  [0,-5,0]])\n",
    "xygp = np.array([[352, 323],\n",
    "                 [382, 290],\n",
    "                 [423, 245],\n",
    "                 [304, 307],\n",
    "                 [239, 286]])\n",
    "tN = np.array([0, 0, 1, 0])\n",
    "P = np.array([[-2.53380724e+01,  1.76724681e+01, -9.75963068e+00, 3.50812662e+02],\n",
    "    [ 8.94324977e+00,  1.92571438e+00, -2.83187164e+01, 3.22243837e+02],\n",
    "    [-2.69423514e-02, -1.94940227e-02, -1.86848368e-02, 1.00000000e+00]])\n",
    "XYZgprec = np.array([reconstruct(tN, P, e2h(xy)) for xy in xygp])\n",
    "print(XYZgprec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well you will see that XYZgp is about the same as XYZgprec. In that case the reconstruct function works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Bonus) The Big Box (0pt, just for fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the calibrated image again where 4 corners of the toy box are indicated. Three of them are on the ground plane, the last one is not and you need to use another plane to reconstruct this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(f)\n",
    "xy_boxcorners = np.array([[55, 222],\n",
    "                          [351, 321],\n",
    "                          [527, 121],\n",
    "                          [314, 69]])\n",
    "plt.scatter(xy_boxcorners[:,0], xy_boxcorners[:,1], marker='x', s=100, c=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is your task to do the reconstruction and use the resulting 3D points to define a 3D wireframe that describes the entire toy box (you may assume that the box is a rectangular one, all angles are 90 degrees). Then use the camera matrix $P$ to project the wireframe and plot it on top of this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d597d2cdabcaa4e0",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Replace this and the following line with your code)\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are really in to it you might want to reproduce the following image showing the reconstruction of (part of) the horizon. Note that all lines are calculated just from the 4 3D points and the projection matrix $P$.\n",
    "<img src=\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_static/box_horizon.png\" width=\"800\" />\n",
    "\n",
    "The green box is the box that you have to draw in the previous bonus exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8fdab69a065a8ade",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE (Replace this and the following line with your code)\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "171.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
