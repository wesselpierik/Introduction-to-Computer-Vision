{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.1: Histogram Equalization\n",
    "\n",
    "## Working with notebooks\n",
    "\n",
    "The assignments for this course will be given as Jupyter notebooks like this one. They will contain programming assignments which are automatically graded.\n",
    "\n",
    "An autograded assignment will typically ask you to complete the code of a Python function. It is important that you do not change the name, inputs or outputs of the function, because they will be tested automatically: stick closely to the assignment. The autograder converts your notebook to a Python file by concatenating all code in the notebook and testing the resulting Python file. It is therefore important that your code runs correctly and uninterrupted, so:\n",
    "\n",
    "**Always use `Kernel > Restart & Run All` and check the results before handing in your assignment**.\n",
    "\n",
    "Some general tips:\n",
    "\n",
    "- Avoid using packages that are not already imported in the assignment template, and are not default Python packages.\n",
    "- Avoid using \"notebook magic\" like `%matplotlib inline`; such commands do not work when the notebook is converted to a Python script.\n",
    "\n",
    "## Working with Codegrade\n",
    "\n",
    "The assignments for this course are automatically graded by a system called *Codegrade*. Our tests will run on your code automatically, and give grades based purely on the correctness of the output.\n",
    "\n",
    "Some of the Codegrade tests will be run immediately, and you can view the output/results before the deadline (it may take a couple of minutes to show up). Use this to check that your code is working correctly, and that you are in the right direction for the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread as skimread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Operators\n",
    "\n",
    "In the lecture notes a point operator is defined as an operator:\n",
    "$$ \n",
    "\\forall \\mathbf x\\in \\mathcal D: \\quad g(\\mathbf x) = \\psi(f(\\mathbf x)),\n",
    "$$\n",
    "where $\\psi$ is a scalar function taking in a gray value (real number) and returning a gray value (real number).\n",
    "\n",
    "We will consider three different implementations of a point operator:\n",
    "\n",
    "1. writing a function based on an analytical expression (e.g. $\\psi(v)=v^2$),\n",
    "2. in case the range of an image $f$ is a discrete and finite set of values (e.g. all pixel values are encoded as 8 bit integers) we can use a **look-up table**, and\n",
    "3. in case an analytical expression is not available but only an (approximate) graph of the function $\\psi$ we can use table interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gamma Correction\n",
    "\n",
    "To warm up for the histogram equalization implementation later on, we first consider **gamma correction**. Let $f$ be a scalar image with gray values in the range from zero to one, then the gamma corrected image $g$ is defined as:\n",
    "$$ \n",
    "\\forall \\mathbf x\\in \\mathcal D: \\quad g(\\mathbf x) = (f(\\mathbf x))^\\gamma\n",
    "$$\n",
    "With the usual overloading of operators we write:\n",
    "$$ \n",
    "g = f^\\gamma\n",
    "$$\n",
    "First, you have to write a function for the gamma correction. (In this case writing a function is unnecessarily complex, but we need it for automatic grading.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_gamma(f, gamma):\n",
    "    \"\"\"\n",
    "    This function returns the array f^gamma: each value in the array f raised to the power gamma.\n",
    "\n",
    "    Note: this function should not use (explicit) loops.\n",
    "    \"\"\"\n",
    "    return f ** gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming $f(\\mathbf x)\\in[0,1]\\subset\\mathbb{R}$ plot the graphs of $f^\\gamma$ in one figure for values $\\gamma \\in\\{ 0.3, 0.5, 0.7, 1, 1.43, 2.0, 3.33 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.linspace(0, 1, 20)\n",
    "f, _ = np.meshgrid(v, np.arange(4))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(f, vmin=0, vmax=1)\n",
    "plt.title(r'$\\gamma=1$')\n",
    "\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "gamma = 0.5\n",
    "plt.imshow(psi_gamma(f, gamma), vmin=0, vmax=1);\n",
    "plt.title('$\\gamma=%5.2f$' % gamma)\n",
    "plt.gray()\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below an 'image' is shown where the gray values increase from zero to one going from left to right. Note that the perceptual difference between the lower gray values (darker tones) is smaller than the difference between the larger gray values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.linspace(0, 1, 20)\n",
    "f, _ = np.meshgrid(v, np.arange(4))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(f, vmin=0, vmax=1)\n",
    "plt.title(r'$\\gamma=1$')\n",
    "\n",
    "plt.gray()\n",
    "plt.axis('off')\n",
    "plt.subplot(2,1,2)\n",
    "gamma = 1.0\n",
    "plt.imshow(psi_gamma(f, gamma), vmin=0, vmax=1); \n",
    "plt.title('$\\gamma=%5.2f$' % gamma)\n",
    "plt.gray()\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the $\\gamma$-curves you should be able to guestimate a value of $\\gamma$ that will result in a more perceptually uniform change of luminance from left to right. Use this value as the $\\gamma$ value in the code above for the second row and observe the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The curve of 0.5 goes up faster in the beginning, making the difference between the darker values bigger, while decreasing the difference between larger gray values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Lookup\n",
    "\n",
    "A (unary) pixel operator can be implemented as a table lookup in case the range of the image is finite and countable. For an 8 bit image this is evidently the case: the possible pixels values are integers in the range from 0 to 255.\n",
    "\n",
    "For such an 8 bit image the gamma correction from the previous section will not work because the gamma correction method assumes that the range is from zero to one. Rewrite the `psi_gamma` function to take an extra keyword argument `max_val` for images in the range from 0 to `max_val`. Note that the resulting image should have the same range from zero to `max_val`. Without special care the resulting image will have floating point values; that is ok for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_gamma_scaled(v, gamma, max_val=1):\n",
    "    v_scaled = v / max_val\n",
    "    adjusted = v_scaled ** gamma\n",
    "    return max_val * adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show two images. The original image 'trui' and a gamma corrected version of it. Note that we start with an image of dtype=uint8 and end up with an image of dtype=float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first time you run these tests, the code downloads the standard computer vision example image \"trui.png\".\n",
    "try:\n",
    "    f = skimread('trui.png')\n",
    "except FileNotFoundError:\n",
    "    import requests\n",
    "    image_file = requests.get(\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_images/trui.png\")\n",
    "    open(\"trui.png\", \"wb\").write(image_file.content)\n",
    "    f = skimread('trui.png')\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(f, vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.title(r'dtype: %s [%d, %d]' % (f.dtype, f.min(), f.max()))\n",
    "plt.subplot(1,2,2)\n",
    "g = psi_gamma_scaled(f, 1.2, max_val=255)\n",
    "plt.imshow(g, vmin=0, vmax=255)\n",
    "plt.title(r'dtype: %s [%5.2f, %5.2f]' % (g.dtype, g.min(), g.max()))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we can simply cast the resulting image into a dtype=uint8 image again but that would not prevent that the calculations (and intermediate images) are dtype=float64. Using a look-up table is one way to prevent that floating point intermediate values are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_table_uint8(gamma):\n",
    "    \"\"\"returns a table (array) T of shape (256,)\"\"\"\n",
    "    T = np.linspace(0, 1, 256, dtype=np.float64)\n",
    "    T_scaled = T ** gamma + 1e-9\n",
    "    T = 255 * T_scaled\n",
    "    T = np.int_(T)\n",
    "    return np.array(T, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below demonstrates the use of table lookup for gamma compression. Note that ``lut[f]`` does the table lookup for all pixels in the image. Read about the 'magic' of array indexing in Numpy to really understand this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(f, vmin=0, vmax=255)\n",
    "plt.axis('off')\n",
    "plt.title(r'dtype: %s [%d, %d]' % (f.dtype, f.min(), f.max()))\n",
    "plt.subplot(1,2,2)\n",
    "lut = gamma_table_uint8(1.2)\n",
    "g = lut[f]\n",
    "plt.imshow(g, vmin=0, vmax=255)\n",
    "plt.title(r'dtype: %s [%d, %d]' % (g.dtype, g.min(), g.max()))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolated Table Lookup\n",
    "\n",
    "A lookup table can only be used in case the set of pixel (gray) values is finite and discrete. For a floating point image a lookup table is not feasible.\n",
    "\n",
    "Consider a point operator characterized with the function $\\psi$:\n",
    "\n",
    "$$\n",
    "g(\\mathbf x) = \\psi(f(\\mathbf x))\n",
    "$$\n",
    "\n",
    "with $f(\\mathbf x)\\in[0,1]\\subset\\mathbb{R}$.\n",
    "\n",
    "Now let $\\psi$ not be given in an analytical form but with just a few samples $\\psi(v_i)=\\psi_i$ (for $i=1,\\ldots,n$). We assume $v_1=0$ and $v_n=1$ and furthermore we assume the sequence $v_i$ is increasing.\n",
    "\n",
    "An example is given in the Python code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([0, 0.25, 0.5, 0.75, 1])\n",
    "psi = np.array([0, 0.1, 0.6, 0.9, 1])\n",
    "plt.plot(v, psi, '-o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only the five points $(v_i, \\psi_i)$ are indicated but also the lines connecting the dots. This is called **linear interpolation**. In a subsequent lab exercise you will have to implement interpolation for 2D functions. Here we will use the Numpy ``interp`` function.\n",
    "\n",
    "To get the value $\\psi(0.6)$ through interpolation (given only the 5 points above) we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psi0p6 = np.interp(0.6, v, psi)\n",
    "print(psi0p6)\n",
    "plt.plot(v, psi, '-o')\n",
    "axs = plt.axis()\n",
    "plt.vlines(0.6, -1, psi0p6, linestyles='dotted')\n",
    "plt.hlines(psi0p6, -1, 0.6, linestyles='dotted')\n",
    "plt.axis(axs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.imread('trui.png')\n",
    "print(f.dtype)\n",
    "g = np.interp(f, v, psi)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(f); \n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(g); \n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the table $\\psi_{\\text{invert}}$ with as few points as possible to invert the image, i.e. $g = 1 - f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_table():\n",
    "    \"\"\"returns a tuple (v, psi) defining a table to be used for\n",
    "    interpolated table lookup that inverts an image\"\"\"\n",
    "    return [0, 1], [1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_inv, psi_inv = invert_table()\n",
    "g = np.interp(f, v_inv, psi_inv)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(f); \n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(g); \n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you have to define the table for interpolated table lookup that thresholds an image:\n",
    "\n",
    "$$\n",
    "\\psi_{t}(v) = \\begin{cases}\n",
    "0 &: v<t\\\\\n",
    "1 &: v\\geq t\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_table(t):\n",
    "    v = [0, t, t, 1]\n",
    "    psi = [0, 0, 1, 1]\n",
    "    return np.array((v, psi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_t, psi_t = threshold_table(0.5)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(f)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(np.interp(f, v_t, psi_t))\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Equalization\n",
    "\n",
    "In the lecture notes the histogram equalization operation for an image with gray values in the range from zero to one is given as the point operator defined with the function:\n",
    "$$\n",
    "\\psi(v) = H_f(v)\n",
    "$$\n",
    "where $H_f$ is the normalized cumulative histogram of the image $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(f, bins=100):\n",
    "    h, be = np.histogram(f, range=(0,1), bins=bins)\n",
    "    H = np.cumsum(h.astype(float)/sum(h))\n",
    "    v = be\n",
    "    psi = np.hstack(([0], H))\n",
    "    return np.interp(f, v, psi)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 64\n",
    "f = plt.imread('trui.png')\n",
    "plt.subplot(321)\n",
    "plt.imshow(f)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(322)\n",
    "g = histogram_equalization(f, bins=bins)\n",
    "plt.imshow(g)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(323)\n",
    "h_f, be_f = np.histogram(f, range=(0,1), bins=bins)\n",
    "h_f = h_f/np.sum(h_f)\n",
    "plt.bar(be_f[:-1], h_f, width=be_f[1]-be_f[0]);\n",
    "\n",
    "plt.subplot(324)\n",
    "h_g, be_g = np.histogram(g, range=(0,1), bins=bins)\n",
    "h_g = h_g/np.sum(h_g)\n",
    "plt.bar(be_g[:-1], h_g, width=be_g[1]-be_g[0])\n",
    "\n",
    "plt.subplot(325)\n",
    "H_f = np.cumsum(h_f)\n",
    "plt.bar(be_f[:-1], H_f, width=be_f[1]-be_f[0])\n",
    "plt.subplot(326)\n",
    "H_g = np.cumsum(h_g)\n",
    "plt.bar(be_g[:-1], H_g, width=be_g[1]-be_g[0]);\n",
    "plt.subplots_adjust(bottom=0.01, top=1.2, right=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do the histogram equilization on an 8 bit image (uint8 data type) you have to write the function ``histogram_equilization_table``. In that function you will need the histogram of the 8bit image. Instead of using the ``histogram`` function, it is better in this case to use the ``bincount`` function from numpy. Be sure to set the ``minlength`` parameter!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization_table(f):\n",
    "    \"\"\"return the lookup table psi_he for the histogram\n",
    "    equalization of an image f (dtype=uint8). Note that the table\n",
    "    should have shape (256,) and dtype=uint8\"\"\"\n",
    "    f = np.ndarray.flatten(f)\n",
    "    his = np.bincount(f, minlength=256)\n",
    "    his = his.astype(float)/sum(his)\n",
    "    his = np.array((255*np.cumsum(his)), dtype=np.uint8)\n",
    "    return his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram Equalization in Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make several (at least 4) pictures of the same scene/object from different points of view. Most likely the overall intensity distribution in the images is not equal due to the automatic lighting correction in your camera. Use histogram equalization to correct for this and comment on whether it does the intended job. In your notebook you have to show a 2 x n ‘matrix’ of images, in the top row the original images and in the bottom row the equalized images.\n",
    "\n",
    "Your camera probably makes color images. Equalization as discussed works on gray value images (black and white images). You can use the function rgb2gray from sklearn.color to make black-and-white images out of your color images.\n",
    "\n",
    "Put the images into the same directory as the notebook, and open them e.g. with `plt.imread`. When uploading your assignment, you can also submit the images: they will be placed in the same directory as your code when the code is run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2gray\n",
    "\n",
    "for i in range(1, 5):\n",
    "    test = plt.imread(f'{i}.jpg')\n",
    "    gray = np.array(255*rgb2gray(test), dtype=np.uint8)\n",
    "    equalization = histogram_equalization_table(gray)\n",
    "    new_image = equalization[gray]\n",
    "    plt.subplot(240+i)\n",
    "    plt.imshow(gray)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(244+i)\n",
    "    plt.imshow(new_image)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equalization does work, since there is much more detail in the third image. And the difference in contrast between the normal version of the first and equalized version is much larger, especially the black area is much darker. The bottom of the fourth image is also much darker, while the highlight is much lighter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus: a simple way to use equalization on color images (and have a color image as the result) is to first convert the color image to a colorspace that explicitly encodes the luminance (the gray value) and the color componenent. One example is the function rgb2hsv from sklearn.color. HSV stands for Hue, Saturation and Value, where value is the gray value component. Equalization of color images then amounts to: convert a rgb image into a hsv image, then equalize the v component and then convert the new hsv image back to rgb (with hsv2rgb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hsv, hsv2rgb\n",
    "\n",
    "def histogram_equalization_rgb(f):\n",
    "    hsv = rgb2hsv(f)\n",
    "    gray = np.array(255*hsv[:,:,2], dtype= np.uint8)\n",
    "    eq = histogram_equalization_table(gray)\n",
    "    equalized = eq[gray]\n",
    "    hsv[:,:,2] = equalized.astype(float) / 255\n",
    "    rgb = hsv2rgb(hsv)\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1.2: Bilinear interpolation\n",
    "\n",
    "In many image processing applications you have access to a number of image transformation methods. These include rotating, stretching and even shearing an image.\n",
    "\n",
    "These methods can be used to create some artistic effect, but they are also useful in correcting things like camera rotation, perspective distortions, etc, that were introduced when the picture was taken.\n",
    "\n",
    "The input for these methods is always a quadrilateral region of a discrete image $F$. That means that you only know the intensity values at discrete integral pixel positions.\n",
    "The output consists of a rectangular image $G$ with axes aligned with the Cartesian coordinate axes $x$ and $y$.\n",
    "\n",
    "In an arbitrary image transformation, there is no guarantee that an \"input\"-pixel will be positioned at a pixel in the \"output\" image as well. Rather, most of the time your output image pixels will \"look at\" image positions in the input image, which are \"between\" pixels.\n",
    "<table><tr> \n",
    "    <td> <img src=\"attachment:pixels_orig.png\"></td>\n",
    "<td> <img src=\"attachment:pixels_rotated.png\"></td>\n",
    "<td> <img src=\"attachment:pixels_both.png\"></td>\n",
    "</tr></table>\n",
    "\n",
    "So you need access to intensity values which are not on the sampling grid of the original image, *e.g.* the intensitiy value at position (6.4, 7.3).\n",
    "\n",
    "In this Exercise you will examine and implement interpolation techniques which solve this problem.\n",
    "In a later assignment you will implement image transformations employing these techniques, such as rotations and projective transformations. This requires determining the desired transformation from the image data or from user input.\n",
    "\n",
    "The relevant theorie for this assignment can be found in the lecture notes in [section 1.4](https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/LectureNotes/IP/Images/ImageInterpolation.html) and in the related theorie questions on ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation\n",
    "\n",
    "The transformation algorithm needs a way to access the original image $F$ in\n",
    "locations that are not on the sampling grid. We thus need a function pixelValue\n",
    "that returns the value in the location $(x,y)$ even for non-integer coordinate\n",
    "values.\n",
    "\n",
    "### A note on indexing\n",
    "\n",
    "There are multiple ways to interpret coordinates in an image. In mathematics, the x-axis usually goes right, and the y-axis goes up. If you have an image file `image`, typically `image[x]` selects a row, and `image[x][y]` then selects a column from that row. That means that the x-axis goes *down*, and the y-axis goes *right*.\n",
    "Another way to do it is to interpret the pixel at coordinates $(x, y)$ as `image[y][x]`: then the x-axis goes right, and the y-axis goes down. (This is almost the same as the standard mathematical way of doing things, except the y-axis now goes down instead of up.) This is the convention we will be applying in this and future notebooks: in particular, the `pixel_value` function will now have inputs `F, y, x` rather than `F, x, y`, and in the case when `y, x` are integers in the domain of `F` it should now return `F[y][x]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a Python function `pixelValue` that returns the value of a pixel at real-valued coordinates $(x, y)$. Fill out the template given in the following cell.\n",
    "\n",
    "You should implement nearest neighbour interpolation (`interpolation_method = 'nearest'`) and\n",
    "bilinear interpolation (`interpolation_method = 'bilinear'`), as are described in the syllabus. Take the necessary steps to deal with the \"border problem\" (*i.e.* implement the function `inImage`). For now you do not yet have to implement any of the other `border_methods`. Instead for now we will simple use the `'constant'` `border_method` to return `cval` when we encounter a point outside of the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_image(image_shape, y, x):\n",
    "    if not 0 <= y <= image_shape[0] - 1:\n",
    "        return False\n",
    "    if not 0 <= x <= image_shape[1] - 1:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def pixel_value(F, y, x, interpolation_method=\"nearest\", border_method=\"constant\", cval=0):\n",
    "    if not in_image(F.shape, y, x):\n",
    "        if border_method == \"constant\":\n",
    "            return cval\n",
    "        elif border_method == \"closest\":\n",
    "            y_new = max(0, min(y, F.shape[0] - 1))\n",
    "            x_new = max(0, min(x, F.shape[1] - 1))\n",
    "            return pixel_value(\n",
    "                F, y_new, x_new, interpolation_method, border_method, cval\n",
    "            )\n",
    "        elif border_method == \"mirror\":\n",
    "            y_shape, x_shape = F.shape[0] - 1, F.shape[1] - 1\n",
    "            new_y = np.abs((y - y_shape) % (2 * y_shape) - y_shape)\n",
    "            new_x = np.abs((x - x_shape) % (2 * x_shape) - x_shape)\n",
    "            return pixel_value(\n",
    "                F, new_y, new_x, interpolation_method, border_method, cval\n",
    "            )\n",
    "        elif border_method == \"wrap\":\n",
    "            new_y, new_x = y % F.shape[0], x % F.shape[1]\n",
    "            if F.shape[0] - 1 < new_y < F.shape[0] or F.shape[1] - 1 < new_x < F.shape[1]:\n",
    "                if interpolation_method == 'bilinear' or interpolation_method == 'linear':\n",
    "                    a = new_x - int(new_x)\n",
    "                    b = new_y - int(new_y)\n",
    "                    y0 = int(new_y)\n",
    "                    y1 = (y0 + 1) % F.shape[0]\n",
    "                    x0 = int(new_x)\n",
    "                    x1 = (x0 + 1) % F.shape[1]\n",
    "                    return ((1 - a) * (1 - b) * pixel_value(F, y0, x0, 'nearest', border_method, cval)\n",
    "                            + a * (1 - b) * pixel_value(F, y0, x1, 'nearest', border_method, cval)\n",
    "                            + (1 - a) * b * pixel_value(F, y1, x0, 'nearest', border_method, cval)\n",
    "                            + a * b * pixel_value(F, y1, x1, 'nearest', border_method, cval))\n",
    "            return pixel_value(\n",
    "                F,\n",
    "                y % (F.shape[0]),\n",
    "                x % (F.shape[1]),\n",
    "                interpolation_method,\n",
    "                border_method,\n",
    "                cval,\n",
    "            )\n",
    "\n",
    "    if interpolation_method == \"nearest\":\n",
    "        return F[int(y + 0.5), int(x + 0.5)]\n",
    "    elif interpolation_method == \"bilinear\" or interpolation_method == 'linear':\n",
    "        a = x - int(x)\n",
    "        b = y - int(y)\n",
    "        return ((1 - a) * (1 - b) * pixel_value(F, int(y), int(x), \"nearest\", border_method, cval)\n",
    "                + a * (1 - b) * pixel_value(F, int(y), int(x) + 1, \"nearest\", border_method, cval)\n",
    "                + (1 - a) * b * pixel_value(F, int(y) + 1, int(x), \"nearest\", border_method, cval)\n",
    "                + a * b * pixel_value(F, int(y) + 1, int(x) + 1, \"nearest\", border_method, cval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# The first time you run these tests, the code downloads the standard computer vision example image \"trui.png\".\n",
    "try:\n",
    "    im = Image.open(\"trui.png\")\n",
    "except FileNotFoundError:\n",
    "    import requests\n",
    "    image_file = requests.get(\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_images/trui.png\")\n",
    "    open(\"trui.png\", \"wb\").write(image_file.content)\n",
    "    im = Image.open(\"trui.png\")\n",
    "image = np.array(im)\n",
    "\n",
    "assert image.shape == (256, 256), \"Did you download the correct image?\"\n",
    "assert in_image(image.shape, 0, 0)\n",
    "assert not in_image(image.shape, -0.5, -0.5)\n",
    "assert in_image(image.shape, image.shape[0] - 1, image.shape[1] - 1)\n",
    "assert not in_image(image.shape, image.shape[0] - 0.5, image.shape[1] - 0.5)\n",
    "assert in_image(image.shape, 0.5, 0.5)\n",
    "assert in_image(image.shape, 0, image.shape[1]/2)\n",
    "assert in_image(image.shape, image.shape[0]/3, image.shape[1]/1.5)\n",
    "assert not in_image(image.shape, image.shape[0] + 10, image.shape[1] - 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "image = np.array(Image.open(\"trui.png\"))\n",
    "\n",
    "sample_points = [(0, 0), (20, 20), (32.3, 39.6), (100.7, 21.2), (14.9, 142.9), \n",
    "                 (142.2, 98.1), (-2, 3), (1000.3, 20.5)]\n",
    "nearest_results = [115, 143, 186, 176, 188, 149, 0, 0]\n",
    "\n",
    "for (y, x), v in zip(sample_points, nearest_results):\n",
    "    assert isclose(pixel_value(image, y, x, interpolation_method='nearest'), v), \\\n",
    "        f\"For method nearest, and input point ({y},{x}), you give result \" \\\n",
    "        f\"{pixel_value(image, y, x, interpolation_method='nearest')} instead of {v}.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from math import isclose\n",
    "image = np.array(Image.open(\"trui.png\"))\n",
    "\n",
    "sample_points = [(0, 0), (20, 20), (32.3, 39.6), (100.7, 21.2), (14.9, 142.9), \n",
    "                 (142.2, 98.1), (-2, 3), (1000.3, 20.5)]\n",
    "bilinear_results = [115, 143, 184.24, 175.64, 187.7, 148.56, 0, 0]\n",
    "\n",
    "for (y, x), v in zip(sample_points, bilinear_results):\n",
    "    assert isclose(pixel_value(image, y, x, interpolation_method='bilinear'), v), \\\n",
    "        f\"For method bilinear, and input point ({y},{x}), you give result \" \\\n",
    "        f\"{pixel_value(image, y, x, interpolation_method='bilinear')} instead of {v}.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Perform additional tests of the function `pixel_value` by using the `profile` function that samples an image at `n` equidistant points along a line from $(x_0, y_0)$ to $(x_1, y_1)$. Create a single plot that shows the profile along the same line, using both nearest-neighbor and bilinear interpolation, that clearly shows the difference between the two methods. (Hint: if you take `n` high enough, the difference should be clear.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(image, y0, x0, y1, x1, n, method):\n",
    "    xs = np.linspace(y0, y1, n)\n",
    "    ys = np.linspace(x0, x1, n)\n",
    "    return np.array([pixel_value(image, y, x, interpolation_method=method) for y, x in zip(ys, xs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "image = np.array(Image.open(\"trui.png\"))\n",
    "\n",
    "nn = profile(image, 0, 0, 20, 0, 1000, 'nearest')\n",
    "bl = profile(image, 0, 0, 20, 0, 1000, 'bilinear')\n",
    "xs = np.linspace(0, 20, 1000)\n",
    "plt.plot(xs, nn)\n",
    "plt.plot(xs, bl);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Now return to the `pixel_value` function and implement the different `border_methods` for the border problem as described in [section 1.5](https://rvdboomgaard.github.io/ComputerVision_LectureNotes/LectureNotes/IP/Images/ImageExtrapolation.html) of the lecture notes.\n",
    "\n",
    "Experiment with these new methods and describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_borders(image, y0, x0, y1, x1, n, border):\n",
    "    xs = np.linspace(x0, x1, n)\n",
    "    ys = np.linspace(y0, y1, n)\n",
    "    return xs, np.array([pixel_value(image, y, x, 'bilinear', border) for y, x in zip(ys, xs)])\n",
    "\n",
    "x0, x1 = 0, 512\n",
    "y0, y1 = 0, 512\n",
    "n = 10000\n",
    "xs, closest = profile_borders(image, y0, x0, y1, x1, n, 'closest')\n",
    "plt.plot(xs, closest, label='closest')\n",
    "xs, mirror = profile_borders(image, y0, x0, y1, x1, n, 'mirror')\n",
    "plt.plot(xs, mirror, label='mirror')\n",
    "xs, wrap = profile_borders(image, y0, x0, y1, x1, n, 'wrap')\n",
    "plt.plot(xs, wrap, label='wrap')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the graph above, the difference between the different kinds of border methods is quite significant.\n",
    "The closest function just constantly the last value that it encountered while going through the image. Wrapping repeats the same image infinitely, while mirroring flips the image."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
