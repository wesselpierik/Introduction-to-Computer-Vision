{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interim-jungle",
   "metadata": {},
   "source": [
    "# Guide: Convolutions and local structure\n",
    "\n",
    "The assignments for this week is given in a separate notebook. This notebook just contains examples and is not graded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True) # change this in case you need more precision\n",
    "\n",
    "# The config below gives neat plots, remove if it is not working in your setup\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-knight",
   "metadata": {},
   "source": [
    "In this lab we will often find the need to show images side by side for comparison. A function to do so is given here. You may skip this section and just use the function where needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_row(imttllist, axs=False):\n",
    "    n = len(imttllist)\n",
    "    for i, imttl in enumerate(imttllist):\n",
    "        if imttl is None:\n",
    "            continue\n",
    "        im, ttl = imttl\n",
    "        plt.subplot(1,n,i+1)\n",
    "        plt.imshow(im, cmap='gray')\n",
    "        if not axs:\n",
    "            plt.axis('off')\n",
    "        plt.title(ttl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-seattle",
   "metadata": {},
   "source": [
    "## 1. Convolutions\n",
    "\n",
    "The definition for the convolution $G=F\\star W$ of two discrete\n",
    "functions $F$ and $W$ is:\n",
    "\\begin{align}\n",
    "   G[i,j] = \\sum_{k=-\\infty}^\\infty \\sum_{l=-\\infty}^\\infty F[i-k,j-l] W[k,l]\n",
    "\\end{align}\n",
    "The recipe to calculate the convolution is:\n",
    "\n",
    "1. Mirror the function $W$ in the origin to give function\n",
    "   $W^m[i,j]=W[-i,-j]$,\n",
    "\n",
    "1. then shift the weight function $W^m$ to position $(k,l)$ in the image, \n",
    "\n",
    "1. pixelwise multiply the function and shifted weight function and\n",
    "\n",
    "1. sum all resulting values, this is the result of the convolution at point $(i,j)$.\n",
    "\n",
    "Let's do this for a simple example. Below you see a small image $F$\n",
    "and a weight function $W$. Here we use the convention that when\n",
    "drawing weight functions (also called kernels) we assume it is defined\n",
    "over the infinite two dimensional domain, but we indicate only those\n",
    "values different from zero (note that points $(k,l)$ such that\n",
    "$W[k,l]=0$ do not add to the convolution result, we simply can ignore\n",
    "those points). In particular, the origin of the function represented by the weight matrix $W$ is assumed to be in the center of the matrix given (see also the explanation a few cells down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.random.randint(0,10,(11,11))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.ones((3,3))/9\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = convolve(F, W)\n",
    "print(G)\n",
    "print(G.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-recommendation",
   "metadata": {},
   "source": [
    "Note that the dtype of array G is ``int64`` (or maybe another integral type, depending on your exact system) although an average is calculated. That is not as Python itself would handle this (it would return a floating point value). In the convolve function by default the resulting array will keep the dtype from the input image (first argument, irrespective of the dtype of the kernel, the second argument). In an image processing context this is a logical choice but for us it is annoying. You can override the default behavious with named argument ``output=np.float64``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = convolve(F, W, output=np.float64)\n",
    "print(G)\n",
    "print(G.dtype)\n",
    "np.convolve([1, 2, 3], [0, 1, 0.5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-sector",
   "metadata": {},
   "source": [
    "Answer the following questions for yourself to ensure you understand what's going on.\n",
    "\n",
    "1. Calculate the convolution value G[5, 0] and G[5, 5] by hand and compare it with the result above. \n",
    "\n",
    "2. Note that G[5, 0] is a value on the border. The 3x3 neighborhood is partly outside the domain of image F. What mode for the border is the convolve function using by default (we didn't specify it explicitly)? Hint: try the `?convolve` command.\n",
    "\n",
    "3. Try some other modes for handling the border and see if you can calculate the results also by hand.\n",
    "\n",
    "Using a very simple 48x48 image you have to convolve that image with various weight kernels to get an understanding of what convolution is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    f_smiley = plt.imread('smiley.png')[:,:,1]\n",
    "except FileNotFoundError:\n",
    "    wget.download(\"https://rvdboomgaard.github.io/ComputerVision_LectureNotes/_static/smiley.png\")\n",
    "    f_smiley = plt.imread('smiley.png')[:,:,1]\n",
    "plt.imshow(f_smiley, cmap='gray');\n",
    "print(f_smiley.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-arthur",
   "metadata": {},
   "source": [
    "We start with a $5\\times5$ average filter\n",
    "\\begin{equation}\\label{eq:five}\n",
    "f \\ast \\frac{1}{25} \\begin{bmatrix}\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & \\underline1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "W5x5 = np.ones((5,5))/25\n",
    "g_smiley_5x5 = convolve(f_smiley, W5x5)\n",
    "imshow_row([(f_smiley,\"original f\"), (g_smiley_5x5, r\"$f\\ast W_{5\\times5}$\")], axs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-promise",
   "metadata": {},
   "source": [
    "You should be aware that something 'strange' is happening here. It indeeds is true that the ``convolve`` function implements the convolution that was given in the equation just above. That is indeed strange as the origin of the array (image is in the top left pixel, with x running from left to right and y running from top to bottom). So the convolve function somehow set the origin to be in the center of the array. And indeed it does. Read the documentation.\n",
    "\n",
    "In the ``convolve`` function we can override the position of the origin. Let's do the convolution\n",
    "\\begin{equation}\\label{eq:fivetopleft}\n",
    "f \\ast \\frac{1}{25} \\begin{Bmatrix}\n",
    "    \\underline1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\\\\\n",
    "    1 & 1 & 1 & 1 & 1\n",
    "    \\end{Bmatrix}\n",
    "\\end{equation}\n",
    "Before you run the next cell, what do you think will be the difference with the kernel with origin in the center?\n",
    "\n",
    "Note that the ``origin`` named argument of the convolution function is relative to the assumed origin in the center of the array passed to the function as argument ``weights``. So ``origin=(-2,-2)`` sets the origin to the top left element in the (5,5) shaped array ``W5x5``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_smiley_tl = convolve(f_smiley, W5x5, origin=(-2,-2))\n",
    "imshow_row([(f_smiley,\"original f\"), (g_smiley_tl, r\"$f\\ast W_{5\\times5}$\")], axs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hor_0 = np.zeros((1,41))\n",
    "W_hor_20 = np.zeros((1,41))\n",
    "W_hor_20[0,20] = 1\n",
    "W_hor_0[0,0] = 1\n",
    "g_smiley_hor_20 = convolve(f_smiley, W_hor_0, mode='mirror')\n",
    "g_smiley_hor_0 = convolve(f_smiley, W_hor_20, origin=(0,20), mode='mirror')\n",
    "imshow_row([(f_smiley,\"original f\"), \n",
    "            (g_smiley_hor_20, r\"$f\\ast W_{hor20}$\"),\n",
    "            (g_smiley_hor_0, r\"$f\\ast W_{hor0}$\")], axs=True)\n",
    "if (g_smiley_hor_20 == g_smiley_hor_0).all():\n",
    "    print(\"The two convolutions are the same.\")\n",
    "else:\n",
    "    print(\"Something went wrong.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-container",
   "metadata": {},
   "source": [
    "### Exercise 1a: The pulse function\n",
    "\n",
    "Answer the theory question about the pulse function in ANS. You can check your answers with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Delta(k, l):\n",
    "    m = 2 * np.maximum(np.abs(k), np.abs(l)) + 1\n",
    "    c = m // 2\n",
    "    D = np.zeros((m,m))\n",
    "    D[c+k, c+l] = 1\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Delta(-2,-2))\n",
    "print(Delta(5,3))\n",
    "\n",
    "imshow_row([(f_smiley,\"F\"), (convolve(f_smiley, Delta(5,9)), r\"$F\\ast\\Delta_{(5,9)}$\")], axs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "border_mode = \"constant\"\n",
    "G = convolve(f_smiley, Delta(5,9), mode=border_mode)\n",
    "H = convolve(G, Delta(-5,-9), mode=border_mode)\n",
    "imshow_row([(f_smiley,\"F\"), \n",
    "            (G, r\"$G = F\\ast\\Delta_{(5,9)}$\"),\n",
    "            (H, r\"$H = G\\ast\\Delta_{(-5,-9)}$\")], axs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-quarter",
   "metadata": {},
   "source": [
    "### Exercise 1b: Border modes\n",
    "\n",
    "Try the different border modes in de code above and answer the questions in ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-decade",
   "metadata": {},
   "source": [
    "The problem we saw above can be generalised. The fact that for most border modes $(F\\ast\\Delta_{(k,l)})\\ast\\Delta_{(-k,-l)} \\not= F \\ast (\\Delta_{(k,l)} \\ast \\Delta_{(-k,-l)}) = F\\ast\\Delta_{(0,0)}$ implies that associativity of the convolution operator, as it is true for an unbounded image domain, is not true for images defined on a bounded domain.\n",
    "\n",
    "Associativity is not the only property of convolutions that is not strictly valid in a discrete and bounded domain setting. In theory (in an infinite domain) we have $F\\ast W = W\\ast F$ showing that $F$ and $W$ are to be treated equally. That is not the case in practice as the code snippet below illustrates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_row( [(convolve(f_smiley, W5x5), r\"$F\\ast W_{5\\times5}$\"),\n",
    "             (convolve(W5x5, f_smiley), r\"$W_{5\\times5}\\ast F$\")] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-dispatch",
   "metadata": {},
   "source": [
    "We see that commutativity is not strictly true in the bounded discrete domain. And again by chosing the appropriate border mode *and* embedding the small 5x5 kernel into a larger kernel (the size of the image we want) we can obtain something that looks like commutativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "W48x48 = np.zeros((48,48))\n",
    "W48x48[22:27,22:27] = W5x5\n",
    "imshow_row( [(W48x48, r\"$W_{48\\times48}$\"),\n",
    "             (f_smiley, \"F\"),\n",
    "             (convolve(W48x48, f_smiley, mode=\"wrap\"), r\"$W_{48\\times48} \\ast F$\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-cartoon",
   "metadata": {},
   "source": [
    "### Exercise 1c: Convolution operators\n",
    "\n",
    "Answer the theory question about Convolution operators in ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-method",
   "metadata": {},
   "source": [
    "## 2. Derivative convolutions\n",
    "\n",
    "The weights in the kernel function do not need to be positive. With negative weights in the kernel we can measure differences and therefore derivatives. In the lecture notes (Part 1 Image Processing, section 6.1.2) three different finite difference schemes (convolution kernels) are given to calculate the partial derivative in x direction.\n",
    "\\begin{align}\n",
    "F_x &\\approx F \\ast \\begin{Bmatrix}1 & \\underline {-1} & 0\\end{Bmatrix}\\\\\n",
    "F_x &\\approx F \\ast \\begin{Bmatrix}0 & \\underline {1} & -1\\end{Bmatrix}\\\\\n",
    "F_x &\\approx F \\ast \\frac{1}{2}\\begin{Bmatrix}1 & \\underline {0} & -1\\end{Bmatrix}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dright = np.array([[1,-1,0]])\n",
    "Dleft = np.array([[0,1,-1]])\n",
    "Dcentral = np.array([[1,0,-1]])/2\n",
    "\n",
    "Fxright = convolve(f_smiley, Dright)\n",
    "Fxleft = convolve(f_smiley, Dleft)\n",
    "Fxcentral = convolve(f_smiley, Dcentral)\n",
    "imshow_row([(Fxright, r\"$F \\ast \\{1 \\; -1 \\; 0\\}$\"),\n",
    "            (Fxleft, r\"$F \\ast \\{0 \\; 1 \\; -1\\}$\"),\n",
    "            (Fxcentral, r\"$F \\ast \\{1 \\; 0 \\; -1\\}$\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f_smiley[28], label='F')\n",
    "plt.plot(Fxright[28], label='Fx_right')\n",
    "plt.plot(Fxleft[28], label='Fx_left')\n",
    "plt.plot(Fxcentral[28], label='Fx_center')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-college",
   "metadata": {},
   "source": [
    "### Exercise 1d: Differences\n",
    "\n",
    "Answer the theory question about differences in ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-explorer",
   "metadata": {},
   "source": [
    "## 3. Separable Convolutions\n",
    "\n",
    "An important consequence of the associative property is that some convolution kernels are **dimensionally separable**. Consider the $t\\times7$ kernel, this one can be decomposed as the convolution of a horizontal line of 7 ones and a vertical kernel of 7 ones:\n",
    "\\begin{align}\n",
    "\\begin{Bmatrix}\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & \\underline 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1\n",
    "\\end{Bmatrix} &=\n",
    "\\begin{Bmatrix}\n",
    "1\\\\ 1\\\\ 1\\\\ \\underline 1\\\\ 1\\\\ 1\\\\ 1\n",
    "\\end{Bmatrix}\n",
    "\\ast\n",
    "\\begin{Bmatrix}\n",
    "1 & 1 & 1 & \\underline 1 & 1 & 1 & 1\n",
    "\\end{Bmatrix} \\\\\n",
    "W_{7\\times7} &= W_{7\\times1} \\ast W_{1\\times7}\n",
    "\\end{align}\n",
    "\n",
    "Be sure to understand that the above equality is indeed true, i.e. you should be able to do the convolution in the right hand side and find the kernel in the left hand side. For implementing the convolution\n",
    "\\begin{align}\n",
    "F \\ast W_{7\\times7}\n",
    "\\end{align}\n",
    "we need 49 additions (and multiplications in case the kernel was not a uniform kernel) per pixel. However we can also implement it as\n",
    "\\begin{align}\n",
    "(F\\ast W_{7\\times1})\\ast W_{1\\times7}\n",
    "\\end{align}\n",
    "and then we need only $2\\times 7$ addition/multiplications per pixel.\n",
    "\n",
    "In the next code block you have to time several implementations of a uniform filter of varying sizes. The first convolution to test is\n",
    "\\begin{align}\n",
    "F \\ast W_{N\\times N}\n",
    "\\end{align}\n",
    "with a function call ``convolve(F, np.ones((N, N)))``\n",
    "The second one\n",
    "\\begin{align}\n",
    "(F\\ast W_{N\\times1})\\ast W_{1\\times N}\n",
    "\\end{align}\n",
    "in Python: ``convolve(convolve(F, np.ones((N, 1))), np.ones((1, N)))``\n",
    "and also the ``uniform_filter`` from ``scipy.ndimage``: ``uniform_filter(F, N)``.\n",
    "To help you we give you the basic code to run the three versions of a uniform filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Fcam = plt.imread('cameraman.png')\n",
    "except FileNotFoundError:\n",
    "    wget.download(\"https://staff.fnwi.uva.nl/r.vandenboomgaard/ComputerVision/_images/cameraman.png\")\n",
    "    Fcam = plt.imread('cameraman.png')\n",
    "\n",
    "Fcam_2d_7 = convolve(Fcam, np.ones((7,7)))\n",
    "Fcam_sep_7 = convolve(convolve(Fcam, np.ones((7, 1))), np.ones((1, 7)))\n",
    "from scipy.ndimage import uniform_filter\n",
    "Fcam_scipy = uniform_filter(Fcam, 7)\n",
    "\n",
    "imshow_row([(Fcam, r\"$F$\"),\n",
    "            (Fcam_2d_7, r\"$F\\ast W_{7\\times7}$\")])\n",
    "plt.figure()\n",
    "imshow_row([(Fcam_sep_7, r\"$(F\\ast W_{7\\times1})\\ast W_{1\\times7}$\"),\n",
    "            (Fcam_scipy, \"uniform_filter(F, 7)\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-klein",
   "metadata": {},
   "source": [
    "### Programming exercise 1\n",
    "\n",
    "Time the three versions of the uniform convolution for different values of N in the first exercise of the hand-in notebook for assignment 3. Then answer the questions about your timing diagrams.\n",
    "\n",
    "### Exercise 1e: Sobel filter\n",
    "\n",
    "Answer the theory question about the Sobel filter in ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinct-blend",
   "metadata": {},
   "source": [
    "## 4. Impulse Responses\n",
    "\n",
    "In the lecture notes in the section on [linear local operators](https://rvdboomgaard.github.io/ComputerVision_LectureNotes/LectureNotes/IP/LocalOperators/linearoperators.html#) it was shown that a linear, translation invariant operator is a convolution using the impulse response as the kernel. So given an image filter claimed to be linear and translation invariant we may find the impulse response by running the filter on an image showing a single point with value 1, all other values are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.zeros((11,11))\n",
    "I[5,5] = 1\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniformI = uniform_filter(I, 7)\n",
    "print(uniformI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-castle",
   "metadata": {},
   "source": [
    "Note: we have set the pulse in the middle of the 11x11 image. This means that the origin of the impulse response function is also at that point in the middle.\n",
    "\n",
    "### Programming exercise 2 + 3\n",
    "\n",
    "Now make the programming exercises 2 and 3 in the hand-in notebook for assignment 3.\n",
    "\n",
    "### Exercise 1f. Sobel and Prewitt\n",
    "\n",
    "Answer the theory question about Sobel and Prewitt filters in ANS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-phoenix",
   "metadata": {},
   "source": [
    "## 5. Analytical Derivatives\n",
    "\n",
    "Consider the function $f$ in two variables:\n",
    "\\begin{align}\n",
    "f(x,y) = A\\sin(Vx) + B\\cos(Wy)\n",
    "\\end{align}\n",
    "\n",
    "### Exercise 2a. Partial derivatives\n",
    "\n",
    "Answer the theory question about partial derivatives in ANS.\n",
    "\n",
    "Next we are going to sample the functions $f$, $f_x$ and $f_y$ on a regular grid of 128x128 sample points with $x$ and $y$ values ranging from $-1$ to $1$. We will use a ``meshgrid`` to make two arrays ``X`` and ``Y`` where ``X`` gives the $x$ coordinate for each of the points on the regular grid and ``Y`` gives the $y$ coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-50,51)\n",
    "y = np.arange(-50,51)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-adobe",
   "metadata": {},
   "source": [
    "### Programming exercise 4\n",
    "\n",
    "Now make the programming exercise 4 and write the code to generate the discrete images (sampled functions) ``F``, ``Fx`` and ``Fy``. \n",
    "\n",
    "## 6. Finite Difference Derivatives\n",
    "\n",
    "We are more or less going to repeat the exercise from the previous section. This time for the function:\n",
    "\n",
    "\\begin{align}\n",
    "f(x,y) = 3(1-x)^2 \\exp\\left(-x^2 - (y-1)^2\\right)\n",
    " - 10\\left(\\frac{x}{5} - x^3 - y^5\\right) \\exp\\left(-x^2 - y^2\\right) \n",
    " - \\frac{1}{3} \\exp\\left(-(x+1)^2 - y^2\\right)\n",
    " \\end{align}\n",
    " \n",
    "This is the image that in 3D rendering make up the Matlab logo (consider this a tribute to the legacy of a great program after which many array processing languages are modelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib qt  # use this in case you want an interactive 3D plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "xml = np.linspace(-3, 3, 150)\n",
    "yml = np.linspace(-3, 3, 150)\n",
    "Xml, Yml = np.meshgrid(xml, yml)\n",
    "Fml = 3 * (1-Xml)**2 * np.exp(-(Xml**2) - (Yml+1)**2) \\\n",
    "    - 10 * (Xml/5 - Xml**3 - Yml**5) * np.exp(-Xml**2 - Yml**2) \\\n",
    "    - 1/3 * np.exp(-(Xml+1)**2 - Yml**2) \n",
    "\n",
    "fig = plt.figure(99)\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.imshow(Fml, extent=(-3,3,3,-3), origin='upper');\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "ax2.plot_surface(Xml, Yml, Fml, cmap='copper');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-concert",
   "metadata": {},
   "source": [
    "Like in the previous section we could calculate the partial derivative with respect to $x$ and $y$ analytically (be my guest to do it!). In this section however you have to use the left finite difference convolution from programming exercise 3 to estimate the derivates.\n",
    "\n",
    "### Programming exercise 5\n",
    "\n",
    "Now make the programming exercise 5.\n",
    "\n",
    "## 7. Gaussian Derivatives\n",
    "\n",
    "### Sampling of and Convolution with the Gaussian 2D Function\n",
    "\n",
    "The 2D Gaussian function $G^s(x,y)$ is defined as:\n",
    "\\begin{align}\n",
    "G^s(x,y) = \\frac{1}{s\\sqrt{2\\pi}} e^{-\\frac{x^2+y^2}{2 s^2}}\n",
    "\\end{align}\n",
    "To do a convolution with a Gaussian kernel we have to sample this function on a discrete grid.\n",
    "Note that the function never is zero! For large values of $|x|$ and $|y|$ the function quickly approaches zero fortunately so we may truncate the grid to values $-N, -N+1, \\cdots, -2, -1, 0, 1, 2, \\cdots, N$ for both $x$ and $y$.\n",
    "\n",
    "To generate the grid the ``np.meshgrid`` function can be used again. The selected value for $N$ should of course depend on the scale $s$. In your code you have to set $N$ equal to $\\lceil\\mathtt{factor} \\times \\mathtt{scale}\\rceil$ where ``factor`` is a multiplication factor that influences the approximation error caused by truncating the function.\n",
    "\n",
    "### Programming exercise 6\n",
    "\n",
    "Now make programming exercise 6 and write the code for the 2D Gaussian function. Then answer the questions about the exercise.\n",
    "\n",
    "### Sampling the (Derivative of) the 1D Gauss Function\n",
    "\n",
    "In the lecture notes you can learn that the Gaussian function is the only rotationally symmetric function that can is separable by dimension, i.e.\n",
    "\\begin{align}\n",
    "G^s(x, y) = G^s(x)\\,G^s(y)\n",
    "\\end{align}\n",
    "where we have used $G^s$ to denote both the 2D function as well as the 1D Gaussian function. The context will make this clear. In this subsection only the 1D version of $G^s$ (and its derivatives) are discussed and to be implemented.\n",
    "\n",
    "### Exercise 2b: Gaussian Derivatives\n",
    "\n",
    "Answer the theory question about Gaussian Derivatives in ANS.\n",
    "\n",
    "Evidently $P_1(x)=1$ and it is your task to calculate $P_1(x)$ and $P_2(x)$. Hint: both $P_1$ and $P_2$ are polynomials in $x$. In your code you have to sample (and normalize) $G^s(x)$ and multiply that discrete version with the appropriate sampled version of $P_n(x)$.\n",
    "\n",
    "### Programming exercise 7\n",
    "\n",
    "Now make programming exercise 7 and write the code for the 1D Gaussian function. Test the correctness of your results.\n",
    "\n",
    "### Separable Gaussian (Derivative) Convolution\n",
    "\n",
    "A convolution kernel $w(x,y)$ is called separable in case\n",
    "$$w(x,y) = h(x)\\,v(y)$$\n",
    "where $h$ and $v$ are two 1D functions (where $h$ stands for the horizontal function and $v$ for the vertical function). It is simple to prove that for a separable kernel:\n",
    "\\begin{align}\n",
    "f\\ast w = (f\\ast_h h) \\ast_v v\n",
    "\\end{align}\n",
    "where $f \\ast_h h$ is the 1D convolution of a 2D image $f$ along all its rows with kernel $h$ and $\\ast_v$ is the convolution of an image along all its columns. We have seen this property before for the uniform kernel. There are many separable kernels of course but the Gaussian kernel is the unique kernel that is rotationally symmetric.\n",
    "\n",
    "### Exercise 2c and 2d: Gaussian Derivatives and Seperability\n",
    "\n",
    "Finish the theory question on the Gaussian Derivatives and seperability in ANS.\n",
    "\n",
    "In ``scipy.ndimage`` a special function is available to do one dimensional convolutions along one of the axes of the image array: ``convolve1d``. The ``axis`` named parameter indicates along wich axis the convolution has to be done.\n",
    "\n",
    "### Programming exercise 8\n",
    "\n",
    "Now make programming exercise 8 and write the code for the gD function.\n",
    "\n",
    "## 8. Comparing Derivatives\n",
    "\n",
    "Remember the function\n",
    "\\begin{align}\n",
    "f(x,y) = A\\sin(Vx) + B\\cos(Wy)\n",
    "\\end{align}\n",
    "and its derivatives $f_x$ and $f_y$ that you have calculated before in this lab exercise. Now we are going to compare the analytical results with the results calculated with Gaussian derivative convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(-50,51)\n",
    "y = np.arange(-50,51)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "A = 1\n",
    "B = 2\n",
    "V = 6 * np.pi / 100\n",
    "W = 4 * np.pi / 100\n",
    "\n",
    "# Repeat your code for F, Fx and Fx here (see programming exercise 4):\n",
    "\n",
    "def F_partial_derivatives(X, Y):\n",
    "    A = 1\n",
    "    B = 2\n",
    "    V = 6 * np.pi / 100\n",
    "    W = 4 * np.pi / 100\n",
    "\n",
    "    F = A * np.sin(V * X) + B * np.cos(W * Y)\n",
    "    Fx = A * V * np.cos(V * X)\n",
    "    Fy = -B * W * np.sin(W * Y)\n",
    "\n",
    "    return F, Fx, Fy\n",
    "\n",
    "F, Fx, Fy = F_partial_derivatives(X, Y)\n",
    "\n",
    "imshow_row([(F, r\"$f$\"),\n",
    "            (Fx, r\"$f_x$\"),\n",
    "            (Fy, r\"$f_y$\")])\n",
    "plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat your code for Gauss1d and gd here (see programming exercise 7 and 8):\n",
    "\n",
    "def Gauss1d(scale, order=0, factor=3):\n",
    "    \"\"\"If order=0, this function should give a normalized sample of the 1d Gaussian function,\n",
    "    similar to the Gauss2d function above. If order=1 or order=2, this function should give an\n",
    "    approximation for the first respectively second derivative by multiplying this sample by the\n",
    "    appropriate analytically determined polynomial (see guide notebook).\"\"\"\n",
    "    N = np.ceil(scale * factor).astype(int)\n",
    "\n",
    "    X = np.arange(- N, N + 1)\n",
    "    G = (1 / (scale * np.sqrt(2 * np.pi))) * np.exp(-(X**2) / (2 * scale**2))\n",
    "    G = G / np.sum(G)\n",
    "    if order == 0:\n",
    "        G = G /  np.sum(G)\n",
    "        return X, G\n",
    "    if order == 1:\n",
    "        G = -X * G / scale ** 2\n",
    "        return X, G\n",
    "    if order == 2:\n",
    "        G = (X**2 - scale**2) / scale**4 * G\n",
    "        return X, G\n",
    "\n",
    "from scipy.ndimage import convolve1d\n",
    "\n",
    "def gD(f, scales, orders, factor=3, mode=\"nearest\", cval=0):\n",
    "    \"\"\"\n",
    "    f: the function to convolve\n",
    "    scales: the scales in the x and y direction, respectively\n",
    "    orders: the orders of the derivatives (0 <= order <= 2)\n",
    "    factor: the factor with which you compute the scale to get the size of the domain.\n",
    "    mode, cval: the border mode to use in the convolution, and the constant value in case the mode is `constant`.\n",
    "\n",
    "    returns: the convolution of f with the appropriate Gaussian derivative.\n",
    "    \"\"\"\n",
    "\n",
    "    _, gauss_kernel_horizontal = Gauss1d(scales[0], orders[0], factor)\n",
    "    _, gauss_kernel_vertical = Gauss1d(scales[1], orders[1], factor)\n",
    "\n",
    "    return convolve1d(\n",
    "        convolve1d(f, gauss_kernel_horizontal, axis=0, mode=mode, cval=cval),\n",
    "        gauss_kernel_vertical,\n",
    "        axis=1,\n",
    "        mode=mode,\n",
    "        cval=cval,\n",
    "    )\n",
    "\n",
    "s = 1\n",
    "\n",
    "# Use the function gD to calculate cFx, cFy by Gaussian derivative convolutions.\n",
    "\n",
    "cFx = gD(F, (1, s), (0, 1))\n",
    "cFy = gD(F, (s, 1), (1, 0))\n",
    "\n",
    "imshow_row([(F, r\"$f$\"),\n",
    "            (cFx, r\"$f_x\\approx f \\ast G^1_x$\"),\n",
    "            (cFy, r\"$f_y\\approx f \\ast G^1_y$\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-andorra",
   "metadata": {},
   "source": [
    "Let's compare Fx with cFx by plotting the values along a horizontal line through the center of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-prefix",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(Fx[Fx.shape[0]//2], label=r\"Fx $(f_x)$\")\n",
    "plt.plot(cFx[cFx.shape[0]//2], label=r\"cFx $(f \\ast G^{%5.2f}_x)$\" % s)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-links",
   "metadata": {},
   "source": [
    "### Exercise 2e: Comparing Derivatives\n",
    "\n",
    "Finish the theory question about Comparing Derivatives in ANS.\n",
    "\n",
    "## 5. Canny Edge Detector\n",
    "\n",
    "Finding edges in images is often an important first step in image processing applications. Whereas in the past a lot of edge detectors have been suggested, nowadays most often the Canny edge detector is used.\n",
    "\n",
    "An explanation of the Canny edge detector in terms of local structure as calculated with Gaussian derivatives can be found [here](https://rvdboomgaard.github.io/ComputerVision_LectureNotes/LectureNotes/IP/LocalStructure/CannyEdgeDetector.html#canny-edge-detector)\n",
    "\n",
    "### Programming exercise 9\n",
    "\n",
    "Now make programming exercise 9 and implement the Canny edge detector."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
